{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from pandas import DataFrame, Series\n",
    "from sklearn.feature_selection import RFE, RFECV, SelectFromModel,SelectKBest, f_classif\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, LassoCV, ridge_regression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import platform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'Dividend_Yield', 'sp500_closing', 'PER', 'kodex_open',\n",
       "       'kodex_volume', 'KR_10Y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv('../project1/final_features.csv',index_col=0 )\n",
    "y = pd.read_csv('../project1/y_open_0910.csv')\n",
    "\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns overlap but no suffix specified: Index(['date'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\apps\\ml\\튜터_lead by 유영상\\pipeline_HW.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/%ED%8A%9C%ED%84%B0_lead%20by%20%EC%9C%A0%EC%98%81%EC%83%81/pipeline_HW.ipynb#W2sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m pipeline \u001b[39m=\u001b[39m Pipeline([\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/%ED%8A%9C%ED%84%B0_lead%20by%20%EC%9C%A0%EC%98%81%EC%83%81/pipeline_HW.ipynb#W2sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mpreprocessor\u001b[39m\u001b[39m'\u001b[39m, preprocessor)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/%ED%8A%9C%ED%84%B0_lead%20by%20%EC%9C%A0%EC%98%81%EC%83%81/pipeline_HW.ipynb#W2sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m ])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/%ED%8A%9C%ED%84%B0_lead%20by%20%EC%9C%A0%EC%98%81%EC%83%81/pipeline_HW.ipynb#W2sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Pipeline을 사용하여 데이터 전처리 수행\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/apps/ml/%ED%8A%9C%ED%84%B0_lead%20by%20%EC%9C%A0%EC%98%81%EC%83%81/pipeline_HW.ipynb#W2sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m df_transformed \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(X\u001b[39m.\u001b[39;49mjoin(y), pd\u001b[39m.\u001b[39mDataFrame(pipeline\u001b[39m.\u001b[39mfit_transform(X\u001b[39m.\u001b[39mjoin(y)), columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfeature1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfeature2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mkodex_open\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mopen\u001b[39m\u001b[39m'\u001b[39m]), on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minner\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/%ED%8A%9C%ED%84%B0_lead%20by%20%EC%9C%A0%EC%98%81%EC%83%81/pipeline_HW.ipynb#W2sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# 변환된 데이터프레임 출력\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/%ED%8A%9C%ED%84%B0_lead%20by%20%EC%9C%A0%EC%98%81%EC%83%81/pipeline_HW.ipynb#W2sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mprint\u001b[39m(pd\u001b[39m.\u001b[39mDataFrame(df_transformed, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mDividend_Yield\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msp500_closing\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mkodex_open\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mopen\u001b[39m\u001b[39m'\u001b[39m]))\n",
      "File \u001b[1;32mc:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:9729\u001b[0m, in \u001b[0;36mDataFrame.join\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort, validate)\u001b[0m\n\u001b[0;32m   9566\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjoin\u001b[39m(\n\u001b[0;32m   9567\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   9568\u001b[0m     other: DataFrame \u001b[39m|\u001b[39m Series \u001b[39m|\u001b[39m Iterable[DataFrame \u001b[39m|\u001b[39m Series],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9574\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   9575\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m   9576\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   9577\u001b[0m \u001b[39m    Join columns of another DataFrame.\u001b[39;00m\n\u001b[0;32m   9578\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9727\u001b[0m \u001b[39m    5  K1  A5   B1\u001b[39;00m\n\u001b[0;32m   9728\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 9729\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_join_compat(\n\u001b[0;32m   9730\u001b[0m         other,\n\u001b[0;32m   9731\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[0;32m   9732\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[0;32m   9733\u001b[0m         lsuffix\u001b[39m=\u001b[39;49mlsuffix,\n\u001b[0;32m   9734\u001b[0m         rsuffix\u001b[39m=\u001b[39;49mrsuffix,\n\u001b[0;32m   9735\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m   9736\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m   9737\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:9768\u001b[0m, in \u001b[0;36mDataFrame._join_compat\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort, validate)\u001b[0m\n\u001b[0;32m   9758\u001b[0m     \u001b[39mif\u001b[39;00m how \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcross\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   9759\u001b[0m         \u001b[39mreturn\u001b[39;00m merge(\n\u001b[0;32m   9760\u001b[0m             \u001b[39mself\u001b[39m,\n\u001b[0;32m   9761\u001b[0m             other,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9766\u001b[0m             validate\u001b[39m=\u001b[39mvalidate,\n\u001b[0;32m   9767\u001b[0m         )\n\u001b[1;32m-> 9768\u001b[0m     \u001b[39mreturn\u001b[39;00m merge(\n\u001b[0;32m   9769\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   9770\u001b[0m         other,\n\u001b[0;32m   9771\u001b[0m         left_on\u001b[39m=\u001b[39;49mon,\n\u001b[0;32m   9772\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[0;32m   9773\u001b[0m         left_index\u001b[39m=\u001b[39;49mon \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   9774\u001b[0m         right_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   9775\u001b[0m         suffixes\u001b[39m=\u001b[39;49m(lsuffix, rsuffix),\n\u001b[0;32m   9776\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m   9777\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m   9778\u001b[0m     )\n\u001b[0;32m   9779\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   9780\u001b[0m     \u001b[39mif\u001b[39;00m on \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:162\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    132\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    147\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m    148\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[0;32m    149\u001b[0m         left,\n\u001b[0;32m    150\u001b[0m         right,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         validate\u001b[39m=\u001b[39mvalidate,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[1;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result(copy\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32mc:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:811\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    807\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indicator_pre_merge(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright)\n\u001b[0;32m    809\u001b[0m join_index, left_indexer, right_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_join_info()\n\u001b[1;32m--> 811\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reindex_and_concat(\n\u001b[0;32m    812\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[39m=\u001b[39;49mcopy\n\u001b[0;32m    813\u001b[0m )\n\u001b[0;32m    814\u001b[0m result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_type)\n\u001b[0;32m    816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindicator:\n",
      "File \u001b[1;32mc:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:763\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[1;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[0;32m    760\u001b[0m left \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft[:]\n\u001b[0;32m    761\u001b[0m right \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright[:]\n\u001b[1;32m--> 763\u001b[0m llabels, rlabels \u001b[39m=\u001b[39m _items_overlap_with_suffix(\n\u001b[0;32m    764\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mleft\u001b[39m.\u001b[39;49m_info_axis, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mright\u001b[39m.\u001b[39;49m_info_axis, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuffixes\n\u001b[0;32m    765\u001b[0m )\n\u001b[0;32m    767\u001b[0m \u001b[39mif\u001b[39;00m left_indexer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_range_indexer(left_indexer, \u001b[39mlen\u001b[39m(left)):\n\u001b[0;32m    768\u001b[0m     \u001b[39m# Pinning the index here (and in the right code just below) is not\u001b[39;00m\n\u001b[0;32m    769\u001b[0m     \u001b[39m#  necessary, but makes the `.take` more performant if we have e.g.\u001b[39;00m\n\u001b[0;32m    770\u001b[0m     \u001b[39m#  a MultiIndex for left.index.\u001b[39;00m\n\u001b[0;32m    771\u001b[0m     lmgr \u001b[39m=\u001b[39m left\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mreindex_indexer(\n\u001b[0;32m    772\u001b[0m         join_index,\n\u001b[0;32m    773\u001b[0m         left_indexer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    778\u001b[0m         use_na_proxy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    779\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:2604\u001b[0m, in \u001b[0;36m_items_overlap_with_suffix\u001b[1;34m(left, right, suffixes)\u001b[0m\n\u001b[0;32m   2601\u001b[0m lsuffix, rsuffix \u001b[39m=\u001b[39m suffixes\n\u001b[0;32m   2603\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m lsuffix \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m rsuffix:\n\u001b[1;32m-> 2604\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcolumns overlap but no suffix specified: \u001b[39m\u001b[39m{\u001b[39;00mto_rename\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2606\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrenamer\u001b[39m(x, suffix):\n\u001b[0;32m   2607\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2608\u001b[0m \u001b[39m    Rename the left and right indices.\u001b[39;00m\n\u001b[0;32m   2609\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2620\u001b[0m \u001b[39m    x : renamed column name\u001b[39;00m\n\u001b[0;32m   2621\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: columns overlap but no suffix specified: Index(['date'], dtype='object')"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# 날짜 변환 함수 정의\n",
    "def convert_to_datetime(series):\n",
    "    return series.apply(lambda x: pd.to_datetime(x, format=\"%Y-%m-%d\"))\n",
    "\n",
    "# 데이터 타입 변환 \n",
    "# def convert_to_datatype(series):\n",
    "#    return series.apply(lambda x: x.astype(int))\n",
    "\n",
    "# 시프트 함수 정의\n",
    "def shift_column(series):\n",
    "    return series.shift(-1)\n",
    "\n",
    "# Pipeline 및 ColumnTransformer 생성\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('date_transform', FunctionTransformer(func=convert_to_datetime, validate=False), ['date']),\n",
    "        # ('convert_to_datatype', FunctionTransformer(func=convert_to_datatype, validate=False), ['kodex_open']),  # Fixed function name\n",
    "        ('shift_columns', FunctionTransformer(func=shift_column, validate=False), ['open', 'kodex_open']),\n",
    "        ('imputer', SimpleImputer(strategy='mean'), ['Dividend_Yield', 'sp500_closing']),\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "# Pipeline을 사용하여 데이터 전처리 수행\n",
    "df_transformed = pd.merge(X.join(y), pd.DataFrame(pipeline.fit_transform(X.join(y)), columns=['date', 'feature1', 'feature2', 'kodex_open', 'open']), on='date', how='inner')\n",
    "\n",
    "# 변환된 데이터프레임 출력\n",
    "df_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1363, 1241]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\apps\\ml\\튜터_lead by 유영상\\pipeline_HW.ipynb Cell 4\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/apps/ml/%ED%8A%9C%ED%84%B0_lead%20by%20%EC%9C%A0%EC%98%81%EC%83%81/pipeline_HW.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/apps/ml/%ED%8A%9C%ED%84%B0_lead%20by%20%EC%9C%A0%EC%98%81%EC%83%81/pipeline_HW.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Assuming X and y are your feature matrix and target variable\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/apps/ml/%ED%8A%9C%ED%84%B0_lead%20by%20%EC%9C%A0%EC%98%81%EC%83%81/pipeline_HW.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/%ED%8A%9C%ED%84%B0_lead%20by%20%EC%9C%A0%EC%98%81%EC%83%81/pipeline_HW.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Corrected pipeline variable name\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/%ED%8A%9C%ED%84%B0_lead%20by%20%EC%9C%A0%EC%98%81%EC%83%81/pipeline_HW.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m my_pipeline \u001b[39m=\u001b[39m Pipeline([\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/%ED%8A%9C%ED%84%B0_lead%20by%20%EC%9C%A0%EC%98%81%EC%83%81/pipeline_HW.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mScalling\u001b[39m\u001b[39m'\u001b[39m, StandardScaler()),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/%ED%8A%9C%ED%84%B0_lead%20by%20%EC%9C%A0%EC%98%81%EC%83%81/pipeline_HW.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mFeature_Selection\u001b[39m\u001b[39m'\u001b[39m, SelectKBest(f_classif, k\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/%ED%8A%9C%ED%84%B0_lead%20by%20%EC%9C%A0%EC%98%81%EC%83%81/pipeline_HW.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mRandomForestClassifier\u001b[39m\u001b[39m'\u001b[39m, RandomForestClassifier(max_depth\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m))])\n",
      "File \u001b[1;32mc:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2614\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2611\u001b[0m \u001b[39mif\u001b[39;00m n_arrays \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2612\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAt least one array required as input\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 2614\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39;49marrays)\n\u001b[0;32m   2616\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[0;32m   2617\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2618\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m\n\u001b[0;32m   2619\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:455\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \n\u001b[0;32m    438\u001b[0m \u001b[39mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[39m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    454\u001b[0m result \u001b[39m=\u001b[39m [_make_indexable(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m iterables]\n\u001b[1;32m--> 455\u001b[0m check_consistent_length(\u001b[39m*\u001b[39;49mresult)\n\u001b[0;32m    456\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    407\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    408\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    412\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1363, 1241]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming X and y are your feature matrix and target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Corrected pipeline variable name\n",
    "my_pipeline = Pipeline([\n",
    "    ('Scalling', StandardScaler()),\n",
    "    ('Feature_Selection', SelectKBest(f_classif, k=2)),\n",
    "    ('RandomForestClassifier', RandomForestClassifier(max_depth=3))])\n",
    "\n",
    "my_pipeline.fit(X_train)\n",
    "predictions = my_pipeline.predict(X_test)[:3]\n",
    "accuracy = my_pipeline.score(X_test, y_test)\n",
    "\n",
    "print(\"Predictions:\", predictions)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\apps\\ml\\튜터_lead by 유영상\\pipeline_HW.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/%ED%8A%9C%ED%84%B0_lead%20by%20%EC%9C%A0%EC%98%81%EC%83%81/pipeline_HW.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m          \u001b[39m#Ridge_params = 'alpha':[200, 230, 250,265, 270, 275, 290, 300, 500]}\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/%ED%8A%9C%ED%84%B0_lead%20by%20%EC%9C%A0%EC%98%81%EC%83%81/pipeline_HW.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m grid \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mpipe, param_grid\u001b[39m=\u001b[39mparam, cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/apps/ml/%ED%8A%9C%ED%84%B0_lead%20by%20%EC%9C%A0%EC%98%81%EC%83%81/pipeline_HW.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m grid\u001b[39m.\u001b[39mfit(X_train,y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Feature selection \n",
    "\n",
    "models = {'Lasso': Lasso()}\n",
    "         #'Ridge': ridge_regression()}\n",
    "\n",
    "feature = RFE(LinearRegression(), n_features_to_select=5)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('feature_select',feature),\n",
    "    ('model', models['Lasso'])])\n",
    "\n",
    "param = {'alpha':[0.02, 0.024, 0.025, 0.026, 0.03]}\n",
    "         #Ridge_params = 'alpha':[200, 230, 250,265, 270, 275, 290, 300, 500]}\n",
    "    \n",
    "grid = GridSearchCV(estimator=pipe, param_grid=param, cv=3)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "\n",
    "def model_basic(X_train, y_train, X_test, y_test):\n",
    "    models = [\n",
    "        LogisticRegression(),\n",
    "        SVC(),\n",
    "        RandomForestRegressor(),\n",
    "        XGBRegressor(),\n",
    "        LGBMRegressor()\n",
    "    ]\n",
    "\n",
    "    rdict={'model':[],'MSE':[],'MAE':[],'r2_score':[]}\n",
    "\n",
    "    def model_basic(X_train, y_train, X_test, y_test):\n",
    "    models = [\n",
    "        ('Logistic Regression', LogisticRegression()),\n",
    "        ('SVC', SVC()),\n",
    "        ('Random Forest Regressor', RandomForestRegressor()),\n",
    "        ('XGB Regressor', XGBRegressor()),\n",
    "        ('LGBM Regressor', LGBMRegressor())\n",
    "    ]\n",
    "\n",
    "    rdict = {'model': [], 'MSE': [], 'MAE': [], 'r2_score': []}\n",
    "\n",
    "    for name, clf in models:\n",
    "        pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),  # Use StandardScaler for numerical features\n",
    "            ('classifier', clf)\n",
    "        ])\n",
    "\n",
    "        # Fit the pipeline\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        pred = pipeline.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        results = (\n",
    "            round(mean_squared_error(y_test, pred), 2),\n",
    "            round(mean_absolute_error(y_test, pred), 2),\n",
    "            round(r2_score(y_test, pred), 2)\n",
    "        )\n",
    "\n",
    "        rdict['model'].append(name)\n",
    "        rdict['MSE'].append(results[0])\n",
    "        rdict['MAE'].append(results[1])\n",
    "        rdict['r2_score'].append(results[2])\n",
    "\n",
    "    rdf = pd.DataFrame(data=rdict)\n",
    "    return rdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_model = Pipeline(memory=None,\n",
    "                   steps=[('poly',PolynomialFeatures(degree=2,include_bias=False, interaction_only=False,order='C')),\n",
    "                    ('Linear',LinearRegression(copy_X=True,fit_intercept=True,n_jobs=None))]\n",
    "                    ,verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
