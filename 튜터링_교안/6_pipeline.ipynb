{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "- pipeline 사용법\n",
    "1. class sklearn.pipeline.Pipeline(steps, *, memory=None, verbose=False)\n",
    "    - sklearn.pipeline.Pipeline은 데이터 전처리 및 머신러닝 모델 학습을 하나의 파이프라인으로 묶어주는 scikit-learn 라이브러리의 클래스입니다\n",
    "    - 파라미터의 steps가 튜플의 리스트이다\n",
    "2. sklearn.pipeline.make_pipeline(*steps, memory=None, verbose=False)\n",
    "    - 이 함수는 파이프라인의 단계에 자동으로 이름을 할당하므로 사용자가 각 단계의 이름을 지정할 필요가 없습니다.\n",
    "    - 파라미터의 steps가 객체들의 나열이다\n",
    "    - make_pipeline은 pipeline을 쉽게 사용하기 위한 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](image-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.pipeline 사용법\n",
    "1. 작업명,작업클래스 두 개로 이루어진 튜플을 리스트로 담아서 Pipeline에 담기\n",
    "    - Pipeline([('작업1' , 작업 클래스) , ('작업2' , 작업 클래스)])\n",
    "2. Pipelien 을 fit하기\n",
    "3. Pipeline을 predcit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.pipeline parameters&attribute&methods\n",
    "- Parameters (파라미터):\n",
    "    - steps: 리스트 (List), shape=(n_steps, 2)\n",
    "    - 파이프라인의 각 단계를 정의하는 튜플의 리스트입니다. 각 튜플은 단계의 이름 (문자열)과 단계의 변환기 또는 추정기 (모델)를 지정합니다.\n",
    "\n",
    "- Attributes (어트리뷰트):\n",
    "    - named_steps: dict,파이프라인 단계의 이름과 해당 변환기 또는 모델을 매핑한 사전(Dictionary)입니다.\n",
    "- Methods (메소드):\n",
    "    - fit(X, y=None, **fit_params): 파이프라인을 학습합니다.\n",
    "        - X: 배열 또는 희소 행렬,입력 데이터입니다.\n",
    "        - y: 배열, 기본값=None, 타겟 변수입니다.\n",
    "    - **fit_params: 딕셔너리, 학습 과정에 대한 추가 매개변수입니다.\n",
    "    - fit_transform(X, y=None, **fit_params): 파이프라인을 학습하고 입력 데이터를 변환합니다.\n",
    "    - transform(X): 입력 데이터를 변환합니다.\n",
    "    - predict(X): 입력 데이터에 대한 예측을 수행합니다.\n",
    "    - predict_proba(X): 입력 데이터에 대한 클래스 확률 예측을 수행합니다.\n",
    "    - score(X, y[, sample_weight]): 모델의 성능을 평가합니다.\n",
    "    - get_params([deep]): 파이프라인의 매개변수를 반환합니다.\n",
    "    - set_params(**params): 파이프라인의 매개변수를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8787878787878788"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression,make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 분류할 데이터 생성\n",
    "X, y = make_classification(n_samples=100,n_features=10,n_informative=2 , random_state=42)\n",
    "# 0.33 비율로 트레인 테스트 스플릿\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# pipeline생성 (스케일링과 ,분석방법)\n",
    "pipeline = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf', DecisionTreeClassifier(random_state=112))\n",
    "\t])\n",
    "# 위의 pipeline을 make_pipeline을 이용해서 똑같이 정의하는 방법\n",
    "pilpeline_ = make_pipeline(StandardScaler(), DecisionTreeClassifier(random_state=112))\n",
    "\n",
    "pipeline.fit(X_train,y_train)\n",
    "y_preds=pipeline.predict(X_test)\n",
    "accuracy_score(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9393939393939394"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline2 = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf', LogisticRegression())\n",
    "\t])\n",
    "\n",
    "pipeline2.fit(X_train,y_train)\n",
    "y_preds2=pipeline2.predict(X_test)\n",
    "accuracy_score(y_test,y_preds2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use iris data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf', DecisionTreeClassifier(random_state=112))\n",
    "\t])\n",
    "\n",
    "pipeline.fit(X_train,y_train)\n",
    "y_preds = pipeline.predict(X_test)\n",
    "accuracy_score(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2 = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf', LogisticRegression())\n",
    "\t])\n",
    "\n",
    "pipeline2.fit(X_train,y_train)\n",
    "y_preds2 = pipeline2.predict(X_test)\n",
    "accuracy_score(y_test,y_preds2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. pipeline과 교차검증(k-fold, stratified k-fold)\n",
    "- use sklearn.model_selection.cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](pipeline.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이렇게 하지 않으면, 교차 검증과정에서의 트레인 데이터와 검증 데이터가 모두 학습되고 검증 데이터를 이용해 성능 평가를 하게된다\n",
    "- 그렇게 되면 데이터 누출(data- leakage)문제가 발생하게 된다\n",
    "- 이를 pipeline을 통해 해결할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 0.96666667, 0.9       , 1.        , 1.        ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf', DecisionTreeClassifier())\n",
    "\t])\n",
    "scores = cross_val_score(pipeline,X , y ,scoring='accuracy' ,  cv=5 )\n",
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666668"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. pipeline과 교차검증과 gridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차검증 점수 :  0.9400000000000001\n",
      "최적의 하이퍼 파라메터 조합 : {'clf__max_depth': 3, 'clf__min_samples_split': 4}\n",
      "학습 평가 :  0.96\n",
      "테스트 평가 :  0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split,KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=112)\n",
    "sts = StandardScaler()\n",
    "\n",
    "pipeline=Pipeline([\n",
    "    ('scaler',sts),\n",
    "    ('clf',rfc)\n",
    "])\n",
    "\n",
    "kflod =KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "params = {\n",
    "    \"clf__max_depth\" : [3,5,7,9],\n",
    "    \"clf__min_samples_split\" : [4,6,8]\n",
    "}\n",
    "\n",
    "grid_model = GridSearchCV(estimator=pipeline,\n",
    "                          param_grid=params,\n",
    "                          cv=kflod,\n",
    "                          scoring='accuracy',\n",
    "                          refit=True)\n",
    "\n",
    "grid_model.fit(X_train,y_train)\n",
    "\n",
    "print('교차검증 점수 : ', grid_model.best_score_)\n",
    "print('최적의 하이퍼 파라메터 조합 :', grid_model.best_params_)\n",
    "print('학습 평가 : ', grid_model.score(X_train, y_train))\n",
    "print('테스트 평가 : ', grid_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
